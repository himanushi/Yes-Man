"""
Yes-Manç°¡æ˜“å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆä¾å­˜é–¢ä¿‚å•é¡Œå›é¿ç‰ˆï¼‰
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path

# openWakeWordã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, 'openWakeWord')

def create_simple_training_data():
    """ç°¡æ˜“çš„ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
    print("ğŸ“Š Creating simple training data for Yes-Man...")
    
    # ãƒ€ãƒŸãƒ¼ã®éŸ³å£°ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®å­¦ç¿’ã«ã¯å®Ÿãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ï¼‰
    # ã“ã‚Œã¯æ¦‚å¿µå®Ÿè¨¼ç”¨
    
    output_dir = Path("yes_man_training_data")
    output_dir.mkdir(exist_ok=True)
    
    # æ­£ä¾‹ãƒ‡ãƒ¼ã‚¿ï¼ˆYes-Manï¼‰ã®ãƒ€ãƒŸãƒ¼ç‰¹å¾´é‡
    positive_features = np.random.randn(1000, 16, 96)  # 1000ã‚µãƒ³ãƒ—ãƒ«
    np.save(output_dir / "positive_features.npy", positive_features)
    
    # è² ä¾‹ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ãƒŸãƒ¼ç‰¹å¾´é‡
    negative_features = np.random.randn(5000, 16, 96)  # 5000ã‚µãƒ³ãƒ—ãƒ«
    np.save(output_dir / "negative_features.npy", negative_features)
    
    print(f"âœ… Training data saved to {output_dir}")
    return output_dir

def train_simple_model():
    """ç°¡æ˜“ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
    import torch.nn as nn
    import torch.optim as optim
    
    print("ğŸ§  Training simple Yes-Man detection model...")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data_dir = create_simple_training_data()
    positive = np.load(data_dir / "positive_features.npy")
    negative = np.load(data_dir / "negative_features.npy")
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    X = np.vstack([positive, negative])
    y = np.array([1] * len(positive) + [0] * len(negative))
    
    # ã‚·ãƒ£ãƒƒãƒ•ãƒ«
    indices = np.random.permutation(len(X))
    X = X[indices]
    y = y[indices]
    
    # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
    X_tensor = torch.FloatTensor(X)
    y_tensor = torch.FloatTensor(y).unsqueeze(1)
    
    # ç°¡å˜ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®šç¾©
    class WakeWordModel(nn.Module):
        def __init__(self, input_size=16*96):
            super().__init__()
            self.flatten = nn.Flatten()
            self.fc1 = nn.Linear(input_size, 64)
            self.bn1 = nn.BatchNorm1d(64)
            self.relu1 = nn.ReLU()
            self.fc2 = nn.Linear(64, 32)
            self.bn2 = nn.BatchNorm1d(32)
            self.relu2 = nn.ReLU()
            self.fc3 = nn.Linear(32, 1)
            self.sigmoid = nn.Sigmoid()
        
        def forward(self, x):
            x = self.flatten(x)
            x = self.relu1(self.bn1(self.fc1(x)))
            x = self.relu2(self.bn2(self.fc2(x)))
            x = self.sigmoid(self.fc3(x))
            return x
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    model = WakeWordModel()
    
    # GPUä½¿ç”¨å¯èƒ½ãªã‚‰ä½¿ç”¨
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    X_tensor = X_tensor.to(device)
    y_tensor = y_tensor.to(device)
    
    print(f"ğŸ“ Using device: {device}")
    
    # å­¦ç¿’è¨­å®š
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.BCELoss()
    
    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    batch_size = 32
    epochs = 10
    
    for epoch in range(epochs):
        total_loss = 0
        for i in range(0, len(X_tensor), batch_size):
            batch_X = X_tensor[i:i+batch_size]
            batch_y = y_tensor[i:i+batch_size]
            
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}")
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    output_path = Path("yes_man_model.pth")
    torch.save(model.state_dict(), output_path)
    print(f"âœ… Model saved to {output_path}")
    
    # ONNXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    model.eval()
    dummy_input = torch.randn(1, 16, 96).to(device)
    onnx_path = Path("yes_man_model.onnx")
    
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        export_params=True,
        opset_version=11,
        input_names=['audio_features'],
        output_names=['wake_word_probability'],
        dynamic_axes={'audio_features': {0: 'batch_size'}}
    )
    
    print(f"âœ… ONNX model exported to {onnx_path}")
    print("\nğŸ‰ Training complete! Note: This is a simplified demo.")
    print("For production use, you need:")
    print("1. Real audio data collection")
    print("2. Proper TTS-based synthetic data generation")
    print("3. Audio augmentation pipeline")
    print("4. Extensive validation")

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  Yes-Manç°¡æ˜“å­¦ç¿’ãƒ‡ãƒ¢ (Windowså¯¾å¿œç‰ˆ)     â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    train_simple_model()